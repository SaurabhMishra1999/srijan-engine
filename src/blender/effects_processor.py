import os
import tempfile
import numpy as np
import scipy.io.wavfile as wav
from dotenv import load_dotenv
import google.generativeai as genai

# Load environment variables
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

def detect_effects(script):
    """Detect effects from script keywords."""
    effects = []
    script_lower = script.lower()
    if 'magic' in script_lower or 'divine' in script_lower:
        effects.append('sparkles')
    if 'fire' in script_lower:
        effects.append('smoke')
    return effects

def generate_particle_code(effects):
    """Generate bpy code for particle effects."""
    code = ""
    if 'sparkles' in effects:
        code += """
# Add sparkles particle system
bpy.ops.mesh.primitive_cube_add(size=0.1, location=(0, 0, 2))
emitter = bpy.context.active_object
emitter.name = 'SparklesEmitter'
bpy.ops.object.particle_system_add()
ps = emitter.particle_systems[0]
ps.settings.count = 100
ps.settings.lifetime = 50
ps.settings.emit_from = 'FACE'
ps.settings.physics_type = 'NEWTON'
# Sparkle material
mat = bpy.data.materials.new(name='SparkleMat')
mat.use_nodes = True
mat.node_tree.nodes['Principled BSDF'].inputs['Emission'].default_value = (1, 1, 0.5, 1)
emitter.data.materials.append(mat)
"""
    if 'smoke' in effects:
        code += """
# Add smoke particle system
bpy.ops.mesh.primitive_cube_add(size=0.2, location=(1, 0, 1))
smoke_emitter = bpy.context.active_object
smoke_emitter.name = 'SmokeEmitter'
bpy.ops.object.particle_system_add()
ps_smoke = smoke_emitter.particle_systems[0]
ps_smoke.settings.count = 50
ps_smoke.settings.lifetime = 100
ps_smoke.settings.emit_from = 'VOLUME'
ps_smoke.settings.physics_type = 'NEWTON'
# Smoke material
smoke_mat = bpy.data.materials.new(name='SmokeMat')
smoke_mat.use_nodes = True
smoke_mat.node_tree.nodes['Principled BSDF'].inputs['Transmission'].default_value = 0.8
smoke_emitter.data.materials.append(smoke_mat)
"""
    return code

def generate_music(mood, duration):
    """Generate background music based on mood using scipy (placeholder)."""
    # Placeholder: generate a simple tone
    sample_rate = 44100
    t = np.linspace(0, duration, int(sample_rate * duration), False)
    if mood == 'Intense':
        freq = 220  # A3
        music = np.sin(freq * 2 * np.pi * t) * 0.5
    elif mood == 'Peaceful':
        freq = 440  # A4
        music = np.sin(freq * 2 * np.pi * t) * 0.3
    else:  # Neutral
        freq = 330  # E4
        music = np.sin(freq * 2 * np.pi * t) * 0.4

    # Save to temp wav
    temp_music = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
    wav.write(temp_music.name, sample_rate, (music * 32767).astype(np.int16))
    return temp_music.name

def add_watermark_code():
    """Generate bpy code for watermark."""
    code = """
# Add watermark text
bpy.ops.object.text_add(location=(0.8, -0.8, 0))
watermark = bpy.context.active_object
watermark.data.body = 'Generated by Srijan Engine'
watermark.data.size = 0.05
watermark.data.align_x = 'RIGHT'
watermark.data.align_y = 'BOTTOM'
# Make it always face camera
watermark.constraints.new(type='TRACK_TO')
watermark.constraints['Track To'].target = bpy.context.scene.camera
watermark.constraints['Track To'].track_axis = 'TRACK_NEGATIVE_Z'
"""
    return code

def enhance_export_code(audio_path, music_path, duration, voice_volume=1.0, bgm_volume=0.3):
    """Generate code for VSE export with synced audio."""
    code = f"""
# Set up Video Sequence Editor for syncing
bpy.context.scene.render.resolution_x = 1920
bpy.context.scene.render.resolution_y = 1080
bpy.context.scene.render.fps = 24

# Switch to VSE
bpy.context.window.workspace = bpy.data.workspaces['Video Editing']

# Add video strip (rendered frames)
bpy.ops.sequencer.movie_strip_add(filepath='//render_output.mp4', frame_start=1)

# Add audio strips
if '{audio_path}' != 'None':
    bpy.ops.sequencer.sound_strip_add(filepath='{audio_path}', frame_start=1)
    # Set voice volume
    for strip in bpy.context.scene.sequence_editor.sequences:
        if strip.type == 'SOUND' and strip.frame_start == 1 and strip.channel == 1:
            strip.volume = {voice_volume}
            break

if '{music_path}' != 'None':
    bpy.ops.sequencer.sound_strip_add(filepath='{music_path}', frame_start=1, channel=2)
    # Set BGM volume
    for strip in bpy.context.scene.sequence_editor.sequences:
        if strip.type == 'SOUND' and strip.frame_start == 1 and strip.channel == 2:
            strip.volume = {bgm_volume}
            break

# Set scene end frame
bpy.context.scene.frame_end = int({duration} * 24)
"""
    return code

def process_effects(bpy_code, script, audio_path, mood, duration, enable_bgm=False, voice_volume=1.0, bgm_volume=0.3):
    """Process and add effects to bpy_code."""
    effects = detect_effects(script)
    particle_code = generate_particle_code(effects)
    watermark_code = add_watermark_code()
    music_path = generate_music(mood, duration) if mood and enable_bgm else None
    export_code = enhance_export_code(audio_path, music_path, duration, voice_volume, bgm_volume)

    bpy_code += "\n\n" + particle_code + "\n\n" + watermark_code + "\n\n" + export_code
    return bpy_code